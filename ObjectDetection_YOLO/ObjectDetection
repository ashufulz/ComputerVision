import cv2
import numpy as np

video = 'path\to\video\file'
output_video_path = 'path\to\output\video\file'

file_name = video.split("\\")[-1].split('.')[0]
file_ext = video.split("\\")[-1].split('.')[1]        # mp4 / avi

OUTPUT_PATH = output_video_path + "\\" + file_name + '.' + file_ext

# Variable Initialization
weights = 'path\to\weights\file'
configuration = 'path\to\config\file'
classFile = 'path\to\COCO_names\file'

FOUR_CC = cv2.VideoWriter_fourcc(*'MP4V')

WIN_WIDTH = 1280
WIN_HEIGHT = 720

OUTPUT = cv2.VideoWriter(OUTPUT_PATH, FOUR_CC, 25.0, (WIN_WIDTH, WIN_HEIGHT))


class ObjectDetection_Yolo:
    def __init__(self):
        # Loading YOLO network
        self.net = cv2.dnn.readNet(weights, configuration)

        self.layer_names = self.net.getLayerNames()
        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]

    def load_classes(self):
        with open(classFile, 'r') as f:
            classes = [line.strip() for line in f.readlines()]

        colors = np.random.uniform(0, 255, size=(len(classes), 3))
        return classes, colors

    def detect(self, filename):
        # Loading Video
        capture = cv2.VideoCapture(filename)

        while True:
            ret, frame = capture.read()
            frame = cv2.resize(frame, (WIN_WIDTH, WIN_HEIGHT))

            height, width, channels = frame.shape

            # Detection objects
            blob = cv2.dnn.blobFromImage(image=frame, scalefactor=0.001, size=(416, 416),
                                         mean=(0, 0, 0), swapRB=True, crop=False)

            self.net.setInput(blob)
            outs = self.net.forward(self.output_layers)

            class_ids = []
            confidences = []
            boxes = []

            for out in outs:
                for detection in out:
                    scores = detection[5:]
                    class_id = np.argmax(scores)
                    confidence = scores[class_id]

                    if confidence > 0.3:
                        center_x = int(detection[0] * width)
                        center_y = int(detection[1] * height)
                        w = int(detection[2] * width)
                        h = int(detection[3] * height)

                        # Box coordinates
                        x = int(center_x - w / 2)
                        y = int(center_y - h / 2)

                        boxes.append([x, y, w, h])
                        confidences.append(float(confidence))
                        class_ids.append(class_id)

            indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

            if len(indexes) > 0:
                for i in indexes.flatten():
                    x, y, w, h = boxes[i]

                    label = str(self.load_classes()[0][class_ids[i]])

                    color = (self.load_classes()[1])[i]
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 2)
                    cv2.putText(frame, label, (x, y - 10), cv2.FONT_ITALIC, 0.75, (255, 255, 255), 2)

            # Save the frames
            OUTPUT.write(frame)

            cv2.imshow('main', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                capture.release()
                break

        cv2.destroyAllWindows()


if __name__ == '__main__':
    od = ObjectDetection_Yolo()
    od.detect(video)
